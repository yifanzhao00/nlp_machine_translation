{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvetKW6AdQfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzfWYJgkdUWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYW4N_ArgzZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\n",
        "from allennlp.data.iterators import BucketIterator\n",
        "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
        "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
        "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.nn.activations import Activation\n",
        "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
        "from allennlp.modules.attention import LinearAttention, BilinearAttention, DotProductAttention\n",
        "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper, StackedSelfAttentionEncoder\n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.predictors import SimpleSeq2SeqPredictor\n",
        "from allennlp.training.trainer import Trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M69HL4gNia5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EN_EMBEDDING_DIM = 256\n",
        "DE_EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bHCXhGJfkse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    reader = Seq2SeqDatasetReader(\n",
        "        source_tokenizer=WordTokenizer(),\n",
        "        target_tokenizer=WordTokenizer(),\n",
        "        source_token_indexers={'tokens': SingleIdTokenIndexer()},\n",
        "        target_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')})\n",
        "    train_dataset = reader.read('./train.tsv')\n",
        "    validation_dataset = reader.read('./dev.tsv')\n",
        "    \n",
        "    vocab = Vocabulary.from_instances(train_dataset + validation_dataset,\n",
        "                                      min_count={'tokens': 3, 'target_tokens': 3})\n",
        "\n",
        "    en_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
        "                             embedding_dim=EN_EMBEDDING_DIM)\n",
        "    encoder = StackedSelfAttentionEncoder(input_dim=EN_EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, projection_dim=128, feedforward_hidden_dim=128, num_layers=1, num_attention_heads=8)\n",
        "\n",
        "    source_embedder = BasicTextFieldEmbedder({\"tokens\": en_embedding})\n",
        "\n",
        "    attention = DotProductAttention()\n",
        "\n",
        "    max_decoding_steps = 40   # TODO: make this variable\n",
        "    model = SimpleSeq2Seq(vocab, source_embedder, encoder, max_decoding_steps,\n",
        "                          target_embedding_dim=EN_EMBEDDING_DIM,\n",
        "                          target_namespace='target_tokens',\n",
        "                          attention=attention,\n",
        "                          beam_size=8,\n",
        "                          use_bleu=True)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      cuda_device = 0\n",
        "      model = model.cuda(cuda_device)\n",
        "    else:\n",
        "      cuda_device = -1\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), weight_decay=0.00002)\n",
        "    iterator = BucketIterator(batch_size=32, sorting_keys=[(\"source_tokens\", \"num_tokens\")])\n",
        "\n",
        "    iterator.index_with(vocab)\n",
        "\n",
        "    trainer = Trainer(model=model,\n",
        "                      optimizer=optimizer,\n",
        "                      iterator=iterator,\n",
        "                      train_dataset=train_dataset,\n",
        "                      validation_dataset=validation_dataset,\n",
        "                      num_epochs=1,\n",
        "                      cuda_device=cuda_device)\n",
        "\n",
        "    for i in range(30):\n",
        "        print('Epoch: {}'.format(i))\n",
        "        trainer.train()\n",
        "\n",
        "        predictor = SimpleSeq2SeqPredictor(model, reader)\n",
        "\n",
        "        for instance in itertools.islice(validation_dataset, 10):\n",
        "            print('SOURCE:', instance.fields['source_tokens'].tokens)\n",
        "            print('GOLD:', instance.fields['target_tokens'].tokens)\n",
        "            print('PRED:', predictor.predict_instance(instance)['predicted_tokens'])\n",
        "        \n",
        "        val_num = 0\n",
        "        for instance in itertools.islice(validation_dataset, 7883):\n",
        "            val_num += 1\n",
        "            if val_num % 100 == 0:\n",
        "                print(val_num)\n",
        "            with open('pred' + str(i), 'a') as the_file:\n",
        "                the_file.write(' '.join(predictor.predict_instance(instance)['predicted_tokens']) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX42ZTX5gsqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Hv6_cIgtqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}